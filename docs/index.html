<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/images/groundctrl_intro1s.gif"/><link rel="preload" as="image" href="/images/cmu.png"/><link rel="preload" as="image" href="/images/fieldai.png"/><link rel="preload" as="image" href="/images/vids-coda2/16_22_gt.gif"/><link rel="preload" as="image" href="/images/vids-scand2/scand_sample_gt.gif"/><link rel="preload" as="image" href="/images/vids-citywalk1/citywalk_sample71_gt.gif"/><link rel="preload" as="image" href="/images/vids-coda1/13_10_gt.gif"/><link rel="preload" as="image" href="/images/vids-scand1/sample_11gt.gif"/><link rel="preload" as="image" href="/images/vids-citywalk2/citywalk_230gt.gif"/><link rel="preload" as="image" href="/images/grndctrl_fig2_v6.png"/><link rel="stylesheet" href="/_next/static/css/14dacc7ba3533e5e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-464b3adafe9e4e9b.js"/><script src="/_next/static/chunks/a8bb8ad9-fc2ec1eca04179b0.js" async=""></script><script src="/_next/static/chunks/525-4bf0f37a1bc3cf60.js" async=""></script><script src="/_next/static/chunks/main-app-923fbad923dbc8c2.js" async=""></script><script src="/_next/static/chunks/976-8ed120f2ef864363.js" async=""></script><script src="/_next/static/chunks/20-50608d3ee5103ab2.js" async=""></script><script src="/_next/static/chunks/app/page-28d67e916c6517f4.js" async=""></script><script src="/_next/static/chunks/ce84277d-606566995e0e358b.js" async=""></script><script src="/_next/static/chunks/app/error-3a2f890f1833ac63.js" async=""></script><title>GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment</title><meta name="description" content="Reinforcement Learning with World Grounding (RLWG) addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards."/><link rel="manifest" href="/favicon/site.webmanifest" crossorigin="use-credentials"/><meta name="robots" content="index, follow"/><meta property="og:title" content="GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment"/><meta property="og:description" content="Reinforcement Learning with World Grounding (RLWG) addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards."/><meta property="og:url" content="https://rlwg-grndctrl.github.io"/><meta property="og:site_name" content="GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://rlwg-grndctrl.github.io/images/og.jpg"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment"/><meta name="twitter:description" content="Reinforcement Learning with World Grounding (RLWG) addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards."/><meta name="twitter:image" content="https://rlwg-grndctrl.github.io/images/og.jpg"/><link rel="shortcut icon" href="/images/icon.png"/><link rel="icon" href="/images/icon.png"/><link rel="apple-touch-icon" href="/images/icon.png"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><main><section class="bg-white text-gray-600 relative flex items-center justify-center h-screen overflow-hidden"><div class="layout z-20 relative flex min-h-screen flex-col items-center justify-center p-4 text-center"><div class="bg-white/40 backdrop-blur-sm rounded-lg px-8 py-6 shadow-lg"><h1 class="mt-4 text-5xl mb-4"><img src="/images/icon.png" alt="GrndCtrl icon" class="h-12 inline-block mr-3 align-middle" loading="lazy"/>GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment</h1><div class="container pb-6 max-w-4xl mx-auto"><div class="text-lg"><span class="text-gray-700"><span><a target="_blank" rel="noopener noreferrer" href="https://purenothingness24.github.io" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Haoyang He</a><sup class="text-gray-700 ml-0.5">1,2</sup><span class="text-gray-500 mx-1">,</span></span><span><a target="_blank" rel="noopener noreferrer" href="https://www.jaypatrikar.me/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Jay Patrikar</a><sup class="text-gray-700 ml-0.5">2</sup><span class="text-gray-500 mx-1">,</span></span><span><a target="_blank" rel="noopener noreferrer" href="https://dkkim93.github.io/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Dong-Ki Kim</a><sup class="text-gray-700 ml-0.5">2</sup><span class="text-gray-500 mx-1">,</span></span><span><a target="_blank" rel="noopener noreferrer" href="https://www.maxosmith.com/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Max Smith</a><sup class="text-gray-700 ml-0.5">2</sup><span class="text-gray-500 mx-1">,</span></span><span><a target="_blank" rel="noopener noreferrer" href="https://danmcgann.com/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Daniel McGann</a><sup class="text-gray-700 ml-0.5">2</sup><span class="text-gray-500 mx-1">,</span></span><span><br/><a target="_blank" rel="noopener noreferrer" href="https://www.fieldai.com/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Ali-akbar Agha-mohammadi</a><sup class="text-gray-700 ml-0.5">2</sup><span class="text-gray-500 mx-1">,</span></span><span><a target="_blank" rel="noopener noreferrer" href="https://www.fieldai.com/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Shayegan Omidshafiei</a><sup class="text-gray-700 ml-0.5">2</sup><span class="text-gray-500 mx-1">,</span></span><span><a target="_blank" rel="noopener noreferrer" href="https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 text-gray-700 hover:text-gray-900">Sebastian Scherer</a><sup class="text-gray-700 ml-0.5">1,2</sup></span></span></div></div><div class="container flex flex-row items-center space-x-8 justify-center text-lg mt-6"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2512.01952" variant="light" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 group gap-[0.25em]"><img src="/svg/arxiv.svg" alt="arXiv logo" class="h-6 w-6 shrink-0" loading="lazy"/><span>arXiv Page</span><svg viewBox="0 0 16 16" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" class="relative transition-transform duration-200 motion-safe:-translate-x-1 group-hover:translate-x-0"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round" class="origin-left transition-all duration-200 opacity-0 motion-safe:-translate-x-1 group-hover:translate-x-0 group-hover:opacity-100"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/RLWG-GrndCtrl/RLWG-GrndCtrl.github.io" variant="light" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 group gap-[0.25em]"><img src="/svg/github.svg" alt="GitHub logo" class="h-6 w-6 shrink-0" loading="lazy"/><span>GitHub Repo</span><svg viewBox="0 0 16 16" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" class="relative transition-transform duration-200 motion-safe:-translate-x-1 group-hover:translate-x-0"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round" class="origin-left transition-all duration-200 opacity-0 motion-safe:-translate-x-1 group-hover:translate-x-0 group-hover:opacity-100"></path></svg></a></div></div></div><img src="/images/groundctrl_intro1s.gif" alt="Background" class="absolute inset-0 w-full h-full object-cover z-0"/><div class="absolute inset-0 z-10 bg-black/40"></div><div class="absolute bottom-4 left-0 z-30 flex flex-row items-center gap-6 text-sm ml-2"><div class="flex items-center gap-2"><span class="text-gray-600 font-semibold text-xs">1</span><img src="/images/cmu.png" alt="Carnegie Mellon University" class="h-6"/></div><div class="flex items-center gap-2"><span class="text-gray-600 font-semibold text-xs">2</span><img src="/images/fieldai.png" alt="Field AI" class="h-7"/></div></div></section><section class="bg-white text-gray-600"><div class="layout py-12"><h2 class="text-center pb-4">Abstract</h2><p class="text-pretty">Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce<b> Reinforcement Learning with World Grounding (RLWG)</b>, a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with <b>GrndCtrl</b>, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, <b>GrndCtrl</b> leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.</p></div></section><section class="bg-dark text-gray-200 py-8"><div class="relative"><div class="flex overflow-x-auto snap-x snap-mandatory scroll-smooth gap-6 px-48 pb-2 scrollbar-dark" aria-label="GrndCtrl highlights slider"><article class="flex-none snap-center w-[85%] md:w-[70%] lg:w-[55%] bg-gray-900/50 border border-white/10 rounded-2xl p-6 shadow-2xl backdrop-blur"><h3 class="text-2xl font-semibold mb-4">Overview</h3><div class="space-y-4 text-base leading-relaxed"><p><b>Reinforcement Learning with World Grounding (RLWG)</b> addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards. Instead of reconstruction losses, RLWG grounds models using geometric and perceptual rewards from frozen evaluators.</p><p><b>GrndCtrl</b> instantiates RLWG using Group Relative Policy Optimization (GRPO), enabling physically consistent rollouts essential for reliable world generation.</p></div></article><article class="flex-none snap-center w-[85%] md:w-[70%] lg:w-[55%] bg-gray-900/50 border border-white/10 rounded-2xl p-6 shadow-2xl backdrop-blur"><h3 class="text-2xl font-semibold mb-4">Problem</h3><div class="space-y-4 text-base leading-relaxed"><p>Despite impressive generative fidelity, current video world models often capture the<em> appearance</em> of motion more than its <em>structure</em>. Their rollouts remain visually plausible but geometrically and temporally inconsistent: poses drift, depths wobble, and trajectories lose alignment over time.</p><p>These instabilities limit the use of current models for closed-loop tasks such as localization, mapping, and planning, where physically consistent representation is essential.</p></div></article><article class="flex-none snap-center w-[85%] md:w-[70%] lg:w-[55%] bg-gray-900/50 border border-white/10 rounded-2xl p-6 shadow-2xl backdrop-blur"><h3 class="text-2xl font-semibold mb-4">Solution</h3><div class="space-y-4 text-base leading-relaxed"><p><b>RLWG</b> refines pretrained world models using verifiable geometric and perceptual rewards derived from model rollouts. Each rollout is automatically scored using rewards that quantify spatial and temporal coherence, such as pose cycle-consistency, depth reprojection agreement, and action adherence.</p><p><b>GrndCtrl</b> uses GRPO to optimize these verifiable rewards efficiently, preserving visual quality while progressively aligning the model&#x27;s dynamics with measurable structure in the real world.</p></div></article></div><div class="pointer-events-none absolute inset-y-0 left-0 w-10 bg-gradient-to-r from-dark to-transparent"></div><div class="pointer-events-none absolute inset-y-0 right-0 w-10 bg-gradient-to-l from-dark to-transparent"></div></div></section><section class="bg-gray-100 text-gray-600"><div class="py-12"><div class="text-center mb-8"><h2 class="pb-4">Qualitative Comparison</h2><p class="text-gray-600">Click to see comparisons of GrndCtrl with ground truth and baseline methods across different scenarios.</p></div><div class="relative"><div class="overflow-x-auto pb-4"><div class="flex gap-6 px-48 min-w-max"><div class="flex-shrink-0 cursor-pointer hover:opacity-80 transition-opacity w-96"><img src="/images/vids-coda2/16_22_gt.gif" alt="CODA 2 ground truth" class="w-full rounded-lg shadow-xl"/></div><div class="flex-shrink-0 cursor-pointer hover:opacity-80 transition-opacity w-96"><img src="/images/vids-scand2/scand_sample_gt.gif" alt="Scand 2 ground truth" class="w-full rounded-lg shadow-xl"/></div><div class="flex-shrink-0 cursor-pointer hover:opacity-80 transition-opacity w-96"><img src="/images/vids-citywalk1/citywalk_sample71_gt.gif" alt="CityWalk 1 ground truth" class="w-full rounded-lg shadow-xl"/></div><div class="flex-shrink-0 cursor-pointer hover:opacity-80 transition-opacity w-96"><img src="/images/vids-coda1/13_10_gt.gif" alt="CODA 1 ground truth" class="w-full rounded-lg shadow-xl"/></div><div class="flex-shrink-0 cursor-pointer hover:opacity-80 transition-opacity w-96"><img src="/images/vids-scand1/sample_11gt.gif" alt="Scand 1 ground truth" class="w-full rounded-lg shadow-xl"/></div><div class="flex-shrink-0 cursor-pointer hover:opacity-80 transition-opacity w-96"><img src="/images/vids-citywalk2/citywalk_230gt.gif" alt="CityWalk 2 ground truth" class="w-full rounded-lg shadow-xl"/></div></div></div><div class="pointer-events-none absolute inset-y-0 left-0 w-10 bg-gradient-to-r from-gray-100 to-transparent"></div><div class="pointer-events-none absolute inset-y-0 right-0 w-10 bg-gradient-to-l from-gray-100 to-transparent"></div></div></div></section><section class="bg-white text-gray-600"><div class="layout py-12"><h2 class="pb-4">Method</h2><figure class="flex flex-col items-center justify-center"><img src="/images/grndctrl_fig2_v6.png" class="w-full h-auto rounded-md pt-4 pb-4 transition invert-0"/><figcaption class="text-gray-600 mt-2 font-light">Figure <!-- -->1<!-- -->. <!-- -->Overview of GrndCtrl. RLWG refines pretrained world models using verifiable geometric and perceptual rewards. GrndCtrl instantiates RLWG using Group Relative Policy Optimization (GRPO) to optimize these rewards, enabling physically consistent rollouts.</figcaption></figure></div></section><section class="bg-white text-gray-600"><div class="layout py-12"><h2 class="pb-4">Quantitative Results</h2><div class="overflow-x-auto"><table class="w-full border-collapse text-sm"><thead><tr class="border-b-2 border-gray-300"><th class="text-left p-2 font-semibold">Method</th><th colSpan="4" class="text-center p-2 font-semibold border-l border-r border-gray-300"><div>Seen</div></th><th colSpan="4" class="text-center p-2 font-semibold border-r border-gray-300"><div>Counterfactual</div></th><th colSpan="4" class="text-center p-2 font-semibold"><div>Unseen</div></th></tr><tr class="border-b border-gray-300"><th class="text-left p-2"></th><th class="text-center p-2 border-l border-gray-300">T↓</th><th class="text-center p-2">R↓</th><th class="text-center p-2">V↑</th><th class="text-center p-2 border-r border-gray-300">DTRI↑</th><th class="text-center p-2">T↓</th><th class="text-center p-2">R↓</th><th class="text-center p-2">V↑</th><th class="text-center p-2 border-r border-gray-300">DTRI↑</th><th class="text-center p-2">T↓</th><th class="text-center p-2">R↓</th><th class="text-center p-2">V↑</th><th class="text-center p-2">DTRI↑</th></tr></thead><tbody><tr><td colSpan="13" class="p-2 font-semibold bg-gray-50 text-center">CODa</td></tr><tr><td class="p-2 pl-4">Baseline</td><td class="text-center p-2 border-l border-gray-200">57.8</td><td class="text-center p-2">1.77</td><td class="text-center p-2">7.40</td><td class="text-center p-2 border-r border-gray-200">38.9</td><td class="text-center p-2">71.5</td><td class="text-center p-2">1.55</td><td class="text-center p-2">7.41</td><td class="text-center p-2 border-r border-gray-200">39.1</td><td class="text-center p-2">56.9</td><td class="text-center p-2">1.71</td><td class="text-center p-2">7.40</td><td class="text-center p-2">38.3</td></tr><tr><td class="p-2 pl-4">+T+R</td><td class="text-center p-2 border-l border-gray-200">46.4</td><td class="text-center p-2">1.44</td><td class="text-center p-2">7.32</td><td class="text-center p-2 border-r border-gray-200">38.4</td><td class="text-center p-2">50.5</td><td class="text-center p-2">1.53</td><td class="text-center p-2">7.34</td><td class="text-center p-2 border-r border-gray-200">38.7</td><td class="text-center p-2">54.3</td><td class="text-center p-2">1.75</td><td class="text-center p-2">7.36</td><td class="text-center p-2">39.3</td></tr><tr><td class="p-2 pl-4">+T+R+DTRI</td><td class="text-center p-2 border-l border-gray-200">65.7</td><td class="text-center p-2">1.74</td><td class="text-center p-2">7.43</td><td class="text-center p-2 border-r border-gray-200">37.0</td><td class="text-center p-2">57.7</td><td class="text-center p-2">1.86</td><td class="text-center p-2">7.42</td><td class="text-center p-2 border-r border-gray-200">36.8</td><td class="text-center p-2">42.6</td><td class="text-center p-2">1.74</td><td class="text-center p-2">7.40</td><td class="text-center p-2">37.1</td></tr><tr class="bg-blue-50"><td class="p-2 pl-4 font-semibold">+T+R+DTRI+V</td><td class="text-center p-2 border-l border-gray-200 font-semibold">39.9</td><td class="text-center p-2 font-semibold">1.27</td><td class="text-center p-2 font-semibold">7.35</td><td class="text-center p-2 border-r border-gray-200 font-semibold">37.5</td><td class="text-center p-2 font-semibold">40.7</td><td class="text-center p-2 font-semibold">1.42</td><td class="text-center p-2 font-semibold">7.34</td><td class="text-center p-2 border-r border-gray-200 font-semibold">37.4</td><td class="text-center p-2 font-semibold">31.0</td><td class="text-center p-2 font-semibold">1.53</td><td class="text-center p-2 font-semibold">7.37</td><td class="text-center p-2 font-semibold">38.0</td></tr><tr><td colSpan="13" class="p-2 font-semibold bg-gray-50 border-t-2 border-gray-300 text-center">SCAND</td></tr><tr><td class="p-2 pl-4">Baseline</td><td class="text-center p-2 border-l border-gray-200">186.3</td><td class="text-center p-2">3.76</td><td class="text-center p-2">7.16</td><td class="text-center p-2 border-r border-gray-200">23.6</td><td class="text-center p-2">315.9</td><td class="text-center p-2">4.24</td><td class="text-center p-2">7.13</td><td class="text-center p-2 border-r border-gray-200">21.4</td><td class="text-center p-2">117.0</td><td class="text-center p-2">4.02</td><td class="text-center p-2">6.99</td><td class="text-center p-2">18.4</td></tr><tr><td class="p-2 pl-4">+T+R</td><td class="text-center p-2 border-l border-gray-200">158.2</td><td class="text-center p-2">3.61</td><td class="text-center p-2">7.19</td><td class="text-center p-2 border-r border-gray-200">23.7</td><td class="text-center p-2">251.2</td><td class="text-center p-2">4.34</td><td class="text-center p-2">7.18</td><td class="text-center p-2 border-r border-gray-200">21.7</td><td class="text-center p-2">131.1</td><td class="text-center p-2">3.95</td><td class="text-center p-2">7.04</td><td class="text-center p-2">19.1</td></tr><tr><td class="p-2 pl-4">+T+R+DTRI</td><td class="text-center p-2 border-l border-gray-200">157.9</td><td class="text-center p-2">3.65</td><td class="text-center p-2">7.10</td><td class="text-center p-2 border-r border-gray-200">22.1</td><td class="text-center p-2">288.6</td><td class="text-center p-2">4.45</td><td class="text-center p-2">7.17</td><td class="text-center p-2 border-r border-gray-200">20.1</td><td class="text-center p-2">118.6</td><td class="text-center p-2">4.07</td><td class="text-center p-2">7.03</td><td class="text-center p-2">17.9</td></tr><tr class="bg-blue-50"><td class="p-2 pl-4 font-semibold">+T+R+DTRI+V</td><td class="text-center p-2 border-l border-gray-200 font-semibold">133.4</td><td class="text-center p-2 font-semibold">3.30</td><td class="text-center p-2 font-semibold">7.11</td><td class="text-center p-2 border-r border-gray-200 font-semibold">24.5</td><td class="text-center p-2 font-semibold">220.1</td><td class="text-center p-2 font-semibold">4.23</td><td class="text-center p-2 font-semibold">7.08</td><td class="text-center p-2 border-r border-gray-200 font-semibold">22.8</td><td class="text-center p-2 font-semibold">123.4</td><td class="text-center p-2 font-semibold">3.62</td><td class="text-center p-2 font-semibold">6.98</td><td class="text-center p-2 font-semibold">19.4</td></tr><tr><td colSpan="13" class="p-2 font-semibold bg-gray-50 border-t-2 border-gray-300 text-center">CityWalk</td></tr><tr><td class="p-2 pl-4">Baseline</td><td class="text-center p-2 border-l border-gray-200">11.7</td><td class="text-center p-2">3.13</td><td class="text-center p-2">7.96</td><td class="text-center p-2 border-r border-gray-200">46.9</td><td class="text-center p-2">13.1</td><td class="text-center p-2">3.27</td><td class="text-center p-2">7.94</td><td class="text-center p-2 border-r border-gray-200">47.4</td><td class="text-center p-2">20.8</td><td class="text-center p-2">4.47</td><td class="text-center p-2">7.90</td><td class="text-center p-2">44.5</td></tr><tr><td class="p-2 pl-4">+T+R</td><td class="text-center p-2 border-l border-gray-200">8.9</td><td class="text-center p-2">3.31</td><td class="text-center p-2">7.90</td><td class="text-center p-2 border-r border-gray-200">44.9</td><td class="text-center p-2">4.8</td><td class="text-center p-2">4.42</td><td class="text-center p-2">7.91</td><td class="text-center p-2 border-r border-gray-200">45.6</td><td class="text-center p-2">10.2</td><td class="text-center p-2">3.47</td><td class="text-center p-2">7.87</td><td class="text-center p-2">42.8</td></tr><tr><td class="p-2 pl-4">+T+R+DTRI</td><td class="text-center p-2 border-l border-gray-200">8.4</td><td class="text-center p-2">3.36</td><td class="text-center p-2">7.84</td><td class="text-center p-2 border-r border-gray-200">43.5</td><td class="text-center p-2">4.7</td><td class="text-center p-2">4.40</td><td class="text-center p-2">7.83</td><td class="text-center p-2 border-r border-gray-200">44.1</td><td class="text-center p-2">10.9</td><td class="text-center p-2">3.68</td><td class="text-center p-2">7.79</td><td class="text-center p-2">41.4</td></tr><tr class="bg-blue-50"><td class="p-2 pl-4 font-semibold">+T+R+DTRI+V</td><td class="text-center p-2 border-l border-gray-200 font-semibold">8.8</td><td class="text-center p-2 font-semibold">3.37</td><td class="text-center p-2 font-semibold">7.84</td><td class="text-center p-2 border-r border-gray-200 font-semibold">42.6</td><td class="text-center p-2 font-semibold">4.7</td><td class="text-center p-2 font-semibold">4.37</td><td class="text-center p-2 font-semibold">7.85</td><td class="text-center p-2 border-r border-gray-200 font-semibold">43.3</td><td class="text-center p-2 font-semibold">9.9</td><td class="text-center p-2 font-semibold">3.74</td><td class="text-center p-2 font-semibold">7.80</td><td class="text-center p-2 font-semibold">40.8</td></tr></tbody></table></div><p class="text-sm text-gray-600 mt-4 text-left">Table 1: Quantitative evaluation across three datasets (<strong>CODa</strong>, <strong>SCAND</strong>, <strong>CityWalk</strong>) and three regimes: <strong>Seen</strong>, <strong>Counterfactual</strong>, and <strong>Unseen</strong>. We compare baseline against progressive reward combinations (T+R, T+R+DTRI, T+R+DTRI+V). GrndCtrl achieves substantial improvements. Metrics: T (Translation Error, m), R (Rotation Error, rad), V (Video Quality), DTRI (Depth Temporal Reprojection Inliers).</p><div class="overflow-x-auto mt-12"><table class="w-full border-collapse text-sm"><thead><tr class="border-b-2 border-gray-300"><th class="text-left p-2 font-semibold">Method</th><th colSpan="2" class="text-center p-2 font-semibold border-l border-r border-gray-300"><div>Seen</div></th><th colSpan="2" class="text-center p-2 font-semibold border-r border-gray-300"><div>Counterfactual</div></th><th colSpan="2" class="text-center p-2 font-semibold"><div>Unseen</div></th></tr><tr class="border-b border-gray-300"><th class="text-left p-2"></th><th class="text-center p-2 border-l border-gray-300">T↓</th><th class="text-center p-2 border-r border-gray-300">R↓</th><th class="text-center p-2">T↓</th><th class="text-center p-2 border-r border-gray-300">R↓</th><th class="text-center p-2">T↓</th><th class="text-center p-2">R↓</th></tr></thead><tbody><tr><td class="p-2 pl-4">Baseline</td><td class="text-center p-2 border-l border-gray-200">73.2 ± 243.7</td><td class="text-center p-2 border-r border-gray-200">2.38 ± 3.88</td><td class="text-center p-2">75.8 ± 253.9</td><td class="text-center p-2 border-r border-gray-200">2.38 ± 3.90</td><td class="text-center p-2">71.2 ± 251.2</td><td class="text-center p-2">2.88 ± 4.28</td></tr><tr><td class="p-2 pl-4">GrndCtrl T+R 100</td><td class="text-center p-2 border-l border-gray-200">72.0 ± 283.6</td><td class="text-center p-2 border-r border-gray-200">1.95 ± 3.38</td><td class="text-center p-2">75.9 ± 311.7</td><td class="text-center p-2 border-r border-gray-200">1.85 ± 3.22</td><td class="text-center p-2">58.4 ± 231.1</td><td class="text-center p-2">2.57 ± 4.08</td></tr><tr><td class="p-2 pl-4">GrndCtrl T+R 150</td><td class="text-center p-2 border-l border-gray-200">26.7 ± 101.5</td><td class="text-center p-2 border-r border-gray-200">1.54 ± 2.84</td><td class="text-center p-2">24.8 ± 99.1</td><td class="text-center p-2 border-r border-gray-200">1.53 ± 2.80</td><td class="text-center p-2">26.5 ± 104.3</td><td class="text-center p-2">2.08 ± 3.33</td></tr><tr class="bg-blue-50"><td class="p-2 pl-4 font-semibold">GrndCtrl T+R 200</td><td class="text-center p-2 border-l border-gray-200 font-semibold">18.4 ± 68.1</td><td class="text-center p-2 border-r border-gray-200 font-semibold">1.40 ± 2.49</td><td class="text-center p-2 font-semibold">16.8 ± 63.0</td><td class="text-center p-2 border-r border-gray-200 font-semibold">1.36 ± 2.57</td><td class="text-center p-2 font-semibold">16.3 ± 56.5</td><td class="text-center p-2 font-semibold">1.97 ± 3.11</td></tr></tbody></table></div><p class="text-sm text-gray-600 mt-4 text-left">Table 2: Reliability analysis showing error statistics (mean ± standard deviation) across multiple stochastic rollouts for different GRPO iterations. Baseline exhibits high variance, while GRPO training progressively reduces both mean errors and variance, achieving consistent rollouts. Metrics: T (Translation Error, m), R (Rotation Error, rad).</p></div></section><section class="bg-gray-100 text-gray-600"><div class="layout pt-4 pb-48"><h2 class="mt-12 mb-4">Citation</h2><pre class="ml-12">@misc{he2025grndctrlgroundingworldmodels,
      title={GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment}, 
      author={Haoyang He and Jay Patrikar and Dong-Ki Kim and Max Smith and Daniel McGann 
              and Ali-akbar Agha-mohammadi and Shayegan Omidshafiei and Sebastian Scherer},
      year={2025},
      eprint={2512.01952},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.01952}, 
}</pre></div></section></main><script src="/_next/static/chunks/webpack-464b3adafe9e4e9b.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/14dacc7ba3533e5e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[2054,[],\"\"]\n4:I[7784,[],\"ClientPageRoot\"]\n5:I[2733,[\"976\",\"static/chunks/976-8ed120f2ef864363.js\",\"20\",\"static/chunks/20-50608d3ee5103ab2.js\",\"931\",\"static/chunks/app/page-28d67e916c6517f4.js\"],\"default\",1]\n6:I[1947,[],\"\"]\n7:I[2354,[\"648\",\"static/chunks/ce84277d-606566995e0e358b.js\",\"976\",\"static/chunks/976-8ed120f2ef864363.js\",\"601\",\"static/chunks/app/error-3a2f890f1833ac63.js\"],\"default\"]\n8:I[8092,[],\"\"]\na:I[2805,[],\"\"]\nb:[]\n0:[\"$\",\"$L2\",null,{\"buildId\":\"qYkkp-Ws4H1fzqP7OFMwE\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"\"],\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L3\",[\"$\",\"$L4\",null,{\"props\":{\"params\":{},\"searchParams\":{}},\"Component\":\"$5\"}],null],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/14dacc7ba3533e5e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$7\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"main\",null,{\"children\":[\"$\",\"section\",null,{\"className\":\"bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"layout flex min-h-screen flex-col items-center justify-center text-center text-black\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"drop-shadow-glow animate-flicker text-red-500\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M4.00098 20V14C4.00098 9.58172 7.5827 6 12.001 6C16.4193 6 20.001 9.58172 20.001 14V20H21.001V22H3.00098V20H4.00098ZM6.00098 14H8.00098C8.00098 11.7909 9.79184 10 12.001 10V8C8.68727 8 6.00098 10.6863 6.00098 14ZM11.001 2H13.001V5H11.001V2ZM19.7792 4.80761L21.1934 6.22183L19.0721 8.34315L17.6578 6.92893L19.7792 4.80761ZM2.80859 6.22183L4.22281 4.80761L6.34413 6.92893L4.92991 8.34315L2.80859 6.22183Z\",\"children\":\"$undefined\"}]]],\"style\":{\"color\":"])</script><script>self.__next_f.push([1,"\"$undefined\"},\"height\":60,\"width\":60,\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"h1\",null,{\"className\":\"mt-8 text-4xl md:text-6xl\",\"children\":\"Page Not Found\"}],[\"$\",\"a\",null,{\"href\":\"/\",\"children\":\"Back to home\"}]]}]}]}],\"notFoundStyles\":[]}]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L9\"],\"globalErrorComponent\":\"$a\",\"missingSlots\":\"$Wb\"}]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Reinforcement Learning with World Grounding (RLWG) addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards.\"}],[\"$\",\"link\",\"4\",{\"rel\":\"manifest\",\"href\":\"/favicon/site.webmanifest\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"5\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Reinforcement Learning with World Grounding (RLWG) addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:url\",\"content\":\"https://rlwg-grndctrl.github.io\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:site_name\",\"content\":\"GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image\",\"content\":\"https://rlwg-grndctrl.github.io/images/og.jpg\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"Reinforcement Learning with World Grounding (RLWG) addresses geometric inconsistencies in pretrained video world models through self-supervised post-training with verifiable rewards.\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://rlwg-grndctrl.github.io/images/og.jpg\"}],[\"$\",\"link\",\"17\",{\"rel\":\"shortcut icon\",\"href\":\"/images/icon.png\"}],[\"$\",\"link\",\"18\",{\"rel\":\"icon\",\"href\":\"/images/icon.png\"}],[\"$\",\"link\",\"19\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icon.png\"}]]\n"])</script><script>self.__next_f.push([1,"3:null\n"])</script></body></html>